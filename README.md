## Facial Expression Recognition 
Facial expression recognition is a project focused on developing a sophisticated system that identifies and classifies human emotions through facial expressions, voice, and body language. Traditional emotion detection methods often require extensive manual intervention and are limited in scope. This project aims to enhance the user experience by providing an automated, efficient solution for recognizing emotions in real time. The system leverages advanced machine learning techniques, including Convolutional Neural Networks (CNN) and Multi-task Cascaded Convolutional Networks (MTCNN), to accurately analyze visual and auditory data.

## Features
1. Utilizes advanced CNN and MTCNN algorithms for robust emotion recognition.
2. Real-time processing for immediate feedback and interaction.
3. Supports multiple input sources, including video streams and audio files.
4. High accuracy in emotion classification through comprehensive training datasets.
5. User-friendly interface for seamless interaction and engagement.
## Requirements
1. Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) to ensure compatibility with deep learning frameworks.
2. Development Environment: Python 3.6 or later is essential for implementing the emotion detection model.
3. Deep Learning Frameworks: TensorFlow is used for model training and implementation.
4. Image Processing Libraries: OpenCV is crucial for real-time video capture and image processing.
5. IDE: Use of PyCharm or VSCode as the Integrated Development Environment for coding, debugging, and version control integration.
6. Additional Dependencies: Includes TensorFlow, OpenCV, NumPy, and other libraries necessary for handling deep learning tasks and data processing.

## System Architecture

![system architecturew (1)](https://github.com/user-attachments/assets/ed739bcd-b037-4d06-9db3-7f2ee7852429)

## Output

#### Output1 - Emotion1
![Screenshot 2024-10-30 111032](https://github.com/user-attachments/assets/1d4be640-6f0e-44c3-911b-aefbe8c8243b)


#### Output2 - Emotion2
![Screenshot 2024-10-30 111133](https://github.com/user-attachments/assets/cdccc9cf-ba50-43dc-84ca-bd9383ed4a15)


## Results and Impact
1. The project's implementation of advanced deep learning techniques and MTCNN for face detection demonstrates significant advancements in the field of affective computing, highlighting its potential for applications in mental health monitoring and interactive technologies.

2. This system lays the groundwork for future developments in emotion recognition technologies, contributing to more responsive and adaptive human-computer interactions that can benefit sectors like education, entertainment, and healthcare.
## Articles published / References
1.Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-Attention with Linear Complexity. In Proceedings of the 37th International Conference on Machine Learning (ICML).Link: https://arxiv.org/abs/2006.04768

2.Ahn, H., Ha, T., Choi, Y., Yoo, H., & Oh, S. (2018). Text2Action: Generative Adversarial Synthesis from Language to Action. In Proceedings of the International Conference on Robotics and Automation (ICRA).Link: https://arxiv.org/abs/1804.03530

3.Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016). Layer Normalization. arXiv preprint arXiv:1607.06450.Link: https://arxiv.org/abs/1607.06450

4.Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural Machine Translation by Jointly Learning to Align and Translate. arXiv preprint arXiv:1409.0473.Link: https://arxiv.org/abs/1409.047

5.Saunders, B., Camgoz, N. C., & Bowden, R. (2021). Continuous 3D Multi-Channel Sign Language Production via Progressive Transformers and Mixture Density Networks. International Journal of Computer Vision, 1â€“23.Link: https://arxiv.org/abs/2104.05347

6.Mollahosseini, A., Chan, D., & Mahoor, M. H. (2017). Going Deeper in Facial Expression Recognition Using Deep Neural Networks. Proceedings of the IEEE International Conference on Computer Vision Workshops (ICCVW).Link: https://arxiv.org/abs/1708.00825

7.Zadeh, A., Chen, M., Poria, S., & Morency, L. P. (2018). Multimodal Emotion Recognition Using Audio, Visual and Textual Cues. In Proceedings of the 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).Link: https://ieeexplore.ieee.org/document/8462642


8. Khalid, S., Shah, A., & Chen, S. (2020). Emotion Recognition from Facial Expressions using Deep Learning: A Comprehensive Review. Artificial Intelligence Review, 53(3), 1439-1455.
https://link.springer.com/article/10.1007/s10462-019-09731-y

9. Ghimire, D., & Hsu, H. (2021). Real-time Facial Emotion Recognition Using Deep Learning and OpenCV. 2021 IEEE International Conference on Smart Computing (SMARTCOMP), 1-8.
https://ieeexplore.ieee.org/document/9472807

10.  Krause, M. R., Kaseb, A., & Tang, Y. (2018). Facial Emotion Recognition: A Comparative Study of Deep Learning Models. Journal of Computer Vision and Image Understanding, 172, 12-20.
https://www.sciencedirect.com/science/article/pii/S1077314218300179




